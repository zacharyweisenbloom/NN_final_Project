{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4fa1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import datetime\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.model_selection\n",
    "\n",
    "import keras_ocr\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "from keras_ocr.detection import Detector\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras_ocr.tools import read\n",
    "\n",
    "data_dir = '.'\n",
    "alphabet = string.digits + string.ascii_letters + '!?. '\n",
    "\n",
    "recognizer_alphabet = ''.join(sorted(set(alphabet.lower())))\n",
    "fonts = keras_ocr.data_generation.get_fonts(alphabet=alphabet, cache_dir=data_dir)\n",
    "\n",
    "backgrounds = keras_ocr.data_generation.get_backgrounds(cache_dir=data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70996a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "import os\n",
    "import csv  \n",
    "def calculate_luminance(color):\n",
    "    # Calculate luminance based on the perceived brightness of RGB values\n",
    "    return 0.299 * color[0] + 0.587 * color[1] + 0.114 * color[2]\n",
    "\n",
    "def get_contrast_color(background_color):\n",
    "    # Choose black or white as the text color based on background luminance\n",
    "    luminance = calculate_luminance(background_color)\n",
    "    return (255, 255, 255) if luminance < 128 else (0, 0, 0)\n",
    "\n",
    "# Set larger image dimensions\n",
    "width, height = 1200, 900\n",
    "\n",
    "# Number of images to generate\n",
    "num_images = 1000\n",
    "\n",
    "# List of words to include in the images\n",
    "word_list = [\"cat\", \"dog\",\"potato\",\"blue\",\"red\",\"green\",\"size\",\"lord\"]\n",
    "\n",
    "\n",
    "output_dir = \"images_no_rotation\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "font_paths = []\n",
    "for font_path in fonts:\n",
    "    font_paths.append(font_path)\n",
    "background_paths = []\n",
    "for background_path in backgrounds:\n",
    "    background_paths.append(background_path)\n",
    "reference_font_size = 1200\n",
    "csv_file_path = \"./image_labels_no_rotation.csv\"\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Image_Path', 'Selected_Word'])\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # Create a blank image\n",
    "        image = Image.new(\"RGB\", (width, height), \"white\")\n",
    "\n",
    "        background_path = random.choice(background_paths)\n",
    "        background = Image.open(background_path)\n",
    "        background = background.resize((width, height))  # Resize the background to match the desired dimensions\n",
    "\n",
    "        # Create a blank image with the background\n",
    "        image = Image.new(\"RGB\", (width, height), \"white\")\n",
    "        image.paste(background, (0, 0))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "\n",
    "\n",
    "        # Randomly select font size and font path\n",
    "        font_size = 400\n",
    "        font_path = random.choice(font_paths)\n",
    "        selected_word = random.choice(word_list)\n",
    "        reference_font = ImageFont.truetype(font_path, reference_font_size)\n",
    "        reference_text_width, reference_text_height = draw.textsize(selected_word, font=reference_font)\n",
    "        scaling_factor = reference_font_size / max(reference_text_width, reference_text_height)\n",
    "        current_font_size = int(reference_font_size * scaling_factor)\n",
    "        font = ImageFont.truetype(font_path, current_font_size)\n",
    "\n",
    "        # Calculate the position to center the word\n",
    "        text_width, text_height = draw.textsize(selected_word, font)\n",
    "        x = (width - text_width) // 2\n",
    "        y = (height - text_height) // 2\n",
    "\n",
    "        # Randomly rotate and scale the text\n",
    "        rotation_angle = random.uniform(-15, 15)\n",
    "        scale_factor = random.uniform(0.8, 1.2)\n",
    "        #X, y = font.getsize(selected_word)\n",
    "        text_layer = Image.new(\"RGBA\", (width, height), (255, 255, 255, 0))\n",
    "        text_draw = ImageDraw.Draw(text_layer)\n",
    "\n",
    "            # Get the background color at the text position\n",
    "        background_color = image.getpixel((x, y))\n",
    "\n",
    "        # Choose the contrasting text color based on background color luminance\n",
    "        text_color = get_contrast_color(background_color)\n",
    "\n",
    "        text_draw.text((x, y), selected_word, font=font, fill=text_color)\n",
    "\n",
    "        rotated_text = text_layer.rotate(rotation_angle, resample=Image.BICUBIC, expand=True)\n",
    "        scaled_text = rotated_text.resize((int(text_width * scale_factor), int(text_height * scale_factor)))\n",
    "        x_centered = (width - scaled_text.width) // 2\n",
    "        y_centered = (height - scaled_text.height) // 2\n",
    "        image.paste(scaled_text, (x_centered, y_centered), scaled_text)\n",
    "\n",
    "\n",
    "        # Save the generated image\n",
    "        image_path = os.path.join(output_dir, f\"generated_image_{i + 1}.png\")\n",
    "        plt.imshow(image)\n",
    "        image.save(image_path)\n",
    "        csv_writer.writerow([image_path, selected_word])\n",
    "\n",
    "\n",
    "print(f\"{num_images} images generated and saved to {output_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa2df1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Load data from the CSV file using pandas\n",
    "csv_file_path = \"./image_labels_no_rotation.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create data generators for training, validation, and test\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Selected_Word',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Selected_Word',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical' \n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Image_Path',\n",
    "    y_col='Selected_Word',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical' \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f646bf5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128,128, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5)) \n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=25,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bab271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "from keras_ocr.detection import Detector\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras_ocr.tools import read\n",
    "\n",
    "test_image_path = \"./test_images/cat.jpg\"\n",
    "\n",
    "\n",
    "# Create a custom text detector/ not being used \n",
    "custom_detector = Detector(weights='clovaai_general')\n",
    "\n",
    "# Create a custom OCR pipeline with only the text detector\n",
    "custom_pipeline = keras_ocr.pipeline.Pipeline()\n",
    "images_not = [\"https://upload.wikimedia.org/wikipedia/commons/b/bd/Army_Reserves_Recruitment_Banner_MOD_45156284.jpg\",\n",
    "              'https://upload.wikimedia.org/wikipedia/commons/b/b4/EUBanana-500x112.jpg']\n",
    "\n",
    "# image url\n",
    "image_urls = [\n",
    "    \"./images_/generated_image_971.png\"\n",
    "]\n",
    "\n",
    "# read and reszize \n",
    "images = [cv2.resize(read(url), (500, 500)) for url in image_urls]\n",
    "\n",
    "# Use the custom detector to detect text in the images\n",
    "detections = custom_pipeline.detector.detect(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "for i, detection in enumerate(detections):\n",
    "    for j, text_info in enumerate(detection):\n",
    "        # Extract coordinates\n",
    "        x_min, y_min = map(int, text_info.min(axis=0))\n",
    "        x_max, y_max = map(int, text_info.max(axis=0))\n",
    "\n",
    "\n",
    "        text_region = images[i][y_min:y_max, x_min:x_max]\n",
    "        cv2.imwrite(f\"text_region_{i + 1}_{j + 1}.png\", text_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = []\n",
    "\n",
    "for i, detection in enumerate(detections):\n",
    "    for j, text_info in enumerate(detection):\n",
    "        # Extract coordinates\n",
    "        x_min, y_min = map(int, text_info.min(axis=0))\n",
    "        x_max, y_max = map(int, text_info.max(axis=0))\n",
    "\n",
    "        # Crop and save the text region\n",
    "        text_region = images[i][y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # Preprocess the image based on your model's requirements\n",
    "        # You may need to normalize pixel values, reshape, or apply other preprocessing steps\n",
    "        preprocessed_text_region = preprocess_input(text_region)\n",
    "\n",
    "\n",
    "        # Make predictions\n",
    "        prediction = model.predict(preprocessed_text_region)\n",
    "\n",
    "        # Append the prediction to the list\n",
    "        predictions.append(prediction)\n",
    "\n",
    "# `predictions` now contains the model predictions for each text region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72ef0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, detection in enumerate(detections):\n",
    "    for j, text_info in enumerate(detection):\n",
    "        # Extract coordinates\n",
    "        x_min, y_min = map(int, text_info.min(axis=0))\n",
    "        x_max, y_max = map(int, text_info.max(axis=0))\n",
    "\n",
    "        # Crop and resize the text region\n",
    "        text_region = cv2.resize(images[i][y_min:y_max, x_min:x_max], (128, 128))\n",
    "\n",
    "        # Preprocess the image based on your model's requirements\n",
    "        # You may need to normalize pixel values, reshape, or apply other preprocessing steps\n",
    "        preprocessed_text_region = preprocess_input(text_region)\n",
    "\n",
    "        # Add a batch dimension (if required by your model)\n",
    "        preprocessed_text_region = np.expand_dims(preprocessed_text_region, axis=0)\n",
    "\n",
    "        # Make predictions\n",
    "        prediction = model.predict(preprocessed_text_region)\n",
    "\n",
    "        # Find the index of the maximum value in the prediction array\n",
    "        predicted_class_index = np.argmax(prediction)\n",
    "\n",
    "        # Get the corresponding class label\n",
    "        predicted_class_label = word_list[predicted_class_index]\n",
    "\n",
    "        # Print the result\n",
    "        print(f\"Prediction for text region {i}, instance {j}: {predicted_class_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af532b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Preprocess the image\n",
    "img_path = './images_no_rotation/generated_image_558.png'\n",
    "img = image.load_img(img_path, target_size=(128, 128))  # Adjust target_size based on your model's input size\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0  # Normalize pixel values\n",
    "\n",
    "# Step 2: Load the model\n",
    "\n",
    "# Step 3: Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)\n",
    "# Step 4: Post-process predictions (example: get the class with the highest probability)\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63bb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a251d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
